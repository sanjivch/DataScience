# Statistics

1. Central Limit Theorem/Tendency
The Central Limit Theorem states that the sampling distribution of the sample means approaches a normal distribution as the sample size gets larger — no matter what the shape of the population distribution. This fact holds especially true for sample sizes over 30. 

1. b Law of Large Numbers
The law of large numbers states that as a sample size grows, its *mean* gets closer to the *average of the whole population*.

1c Under what circumstances


3 How is correlation similar to or different from covariance
Covariance tells us the relationship between two variables. Correlation tells us the strength of the relationship. p-value tells us the statistical significance of the correlation. 
Covariance is hard to interpret as the value changes with scale, however, correlation does not change with scale.

4 Express ANOVA in your own words, share suitable example to explain
ANOVA is method where we check the means of one or more groups are statistically different.

5 What is Mahalanobis distance how is it related to Gaussian distribution


6 What is multi-collinearity? What is its significance?
Correlation between one or more independent variables. Usually identified by the VIF Variance Inflation Factor needs to be closer to 1

7 Please shared your views on Bayes Theorem and it’s link to Likelihood estimation


8 What is entropy, explain the mathematical formulation
Entropy is measure of disorder and in the data sense measure of how unorganised/ messy the data is.

9 Share an example Hypothesis testing you performed recently, How is it fundamentally similar or different from a. Classification problem?


10 Define Goodness of fit test, discuss cases when it is used
R^2 test

Part B


1 In a Regression setting, when do you user R-squared vs RMSE

2 How is classification fundamentally different from Clustering

3 Can a supervised learning setting be thought of as a conditional expectation? If yes, can we say that a supervised learning is inherently biased? Open ended

4 How is Random Forest Regressor different from other Regressors. Please explain using its base formulation (Entropy Info gain)

5 Explain Bias Variance tradeoff

6 What is F measure, under what circumstances can we use it in its base form (Will you use HM every time, Precision recall related)

7 What is regularisation, why is it important. Share regularisation techniques you have used

8 What is convolution, please share an example which does not involve images

9 What are LSTMs, how are they different from CNN

10 How would you go about finding a batch size in a deep learning setting?


Part C


Scenario 1 - Training Data for Classification (5000 cols and 10 mn rows)


A) How do you you go about dimensionality reduction

B) Comment on above if the system has limited memory resources


Scenario 2 - Consider a classical scheduled system (ON TIME PERFORMANCE is IMPORTANT)


How do you go about solving such a business problem and which Machine Learning Techniques would you use for the same


Skills for which Candidates have been evaluated


    Probability Statiscs, NLP, Signal Processing
    Model PP (Autonomous systems)
    LSTMs, GRUs
    CNNs
    SVD
    Fourier transforms and Power transforms
    Word Embeddings, GloVe, NER 
    Seq2Seq models
    Applied Mathematical modeling 
